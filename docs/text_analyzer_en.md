# TextAnalyzer Class

## Overview
A comprehensive text analysis tool for extracting linguistic features, named entities, and special patterns from text data. Designed for both single texts and pandas DataFrames.

## Features
- ðŸ“Š **Text Metrics**: Word count, sentence length, paragraph statistics
- ðŸ” **Pattern Extraction**: Phones, emails, dates, URLs, hashtags
- ðŸ· **Named Entities**: Persons, locations, organizations
- ðŸš€ **DataFrame Support**: Batch processing with parallel execution
- âš™ï¸ **Customizable**: Regex patterns and NLP model configuration

## Installation
```bash
pip install spacy pandas
python -m spacy download en_core_web_sm
```

## Quick Start

```python
from text_analyzer import TextAnalyzer

# Initialize with default config
analyzer = TextAnalyzer()

# Analyze single text
results = analyzer.analyze("This code was auto-generated by DeepSeek v9000.\n"
    "For complaints: not_my_problem@ai.ethics\n"
    "Hotline: +1 (900) AI-BLAME (press 1 to blame the dataset)\n"
    "DISCLAIMER: Human involvement: 0.0001% ðŸ¤–")

# Process DataFrame
df_processed = analyzer.analyze_dataframe(df, text_column="text")
```
## Configuration Reference

The analyzer uses these settings from `config.yaml`

## `analyze_dataframe()` Method

### Full Signature:

```python
analyze_dataframe(
    df: pd.DataFrame,
    text_column: str,
    include_tokens: bool = True,
    drop_original: bool = False,
    parallel: bool = False,
    n_jobs: int = -1
) -> pd.DataFrame
```

### Parameters

| Parameter        | Type          | Default | Description |
|------------------|---------------|---------|-------------|
| `df`             | `pd.DataFrame` | -       | Input DataFrame containing text data |
| `text_column`    | `str`         | -       | Name of column containing texts to analyze |
| `include_tokens` | `bool`        | `True`  | Whether to include token-level features |
| `drop_original`  | `bool`        | `False` | Remove the source text column after processing |
| `parallel`       | `bool`        | `False` | Enable parallel processing (requires `pandarallel`) |
| `n_jobs`         | `int`         | `-1`    | Number of CPU cores for parallel processing (-1 = all cores) |

### Returns:

- Original DataFrame with added columns (prefix `text_`):

```python
{
    # Metrics
    'text_word_count': int,
    'text_avg_word_length': float,
    'text_is_truncated': bool,
    
    # Pattern counts
    'text_phones_count': int,
    'text_emails_count': int,
    
    # Extracted values
    'text_phones': List[str],
    'text_emails': List[str],
    
    # Entities
    'text_persons_count': int,
    'text_locations': List[str]
}
```

### Usage Example:

```python
# Sample DataFrame
df = pd.DataFrame({
    "id": [1, 2],
    "text": [
        "This code was auto-generated by DeepSeek v9000.\n" "For complaints: not_my_problem@ai.ethics\n" "Hotline: +1 (900) AI-BLAME (press 1 to blame the dataset)\n" "DISCLAIMER: Human involvement: 0.0001% ðŸ¤–",
        "hello literally everyone"
    ]
})

# Processing
analyzer = TextAnalyzer(config=config)
result = analyzer.analyze_dataframe(
    df=df,
    text_column="text",
    parallel=True
)

# Output columns will include:
# ['id', 'text', 'text_word_count', 'text_phones', ...]
```
